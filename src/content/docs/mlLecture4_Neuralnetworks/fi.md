---
title: "Machine Learning 4: Neuroverkot"
subtitle: "DATA.ML.100 ¬∑ Joni K√§m√§r√§inen ¬∑ To 4.9.2025 TB104 üòä"
date: "2025-09-08"
lang: "fi"
excerpt: "Neuroverkkojen perusteet: biologisesta inspiraatiosta LTU:ihin, Hebbin oppimiseen, XOR-rajoituksiin, ep√§lineaarisiin aktivointeihin, takaisinlevitykseen ja nykyaikaisiin kehyksiin (TensorFlow & PyTorch)."
tags: ["Joni K√§m√§r√§inen", "koneoppiminen", "neuroverkot", "TensorFlow", "PyTorch"]
draft: false
---

## Osa 1 : Aivoista neuroverkkoihin

![Board notes](/images/docs/mlLecture4_Neuralnetworks/1.png)

### 1.1 Miksi tutkia neuroverkkoja?
- Kun insin√∂√∂rit kohtaavat pullonkauloja, he lainaavat usein ideoita muista tieteist√§ (biologia, ihmistieteet jne.).  
- Ihmisen aivot ovat √§lykk√§in "tietokone", jonka tunnemme, ja ne toimivat koneoppimisen inspiraationa.  

### 1.2 Aivot ja evoluutio
- Aivojen koko on rajoitettu **kallon / synnytyskanavan** vuoksi ‚Äì ne eiv√§t voi kasvaa loputtomiin.  
- My√∂s ravinnon saatavuus vaikuttaa evoluutioon (esim. saarten populaatiot pienenev√§t).  
- Hermosolujen m√§√§r√§ eri lajeissa:
  - Merit√§hdell√§: ~500  
  - Iilimadolla: ~10,000  
  - Banaanik√§rp√§sell√§: ~100,000  
  - Torakalla: ~1,000,000  
  - Kilpikonnalla: ~10,000,000  
  - Hamsterilla: ~100,000,000  
  - P√∂ll√∂ll√§: ~1,000,000,000  
  - Gorillalla: ~30,000,000,000  
  - Ihmisell√§: ~100,000,000,000  
- T√§rkeint√§ ei ole vain hermosolujen m√§√§r√§, vaan **yhteyksien m√§√§r√§** (~$10^{13}$ synapsia ihmisaivoissa).  

### 1.3 Biologisen hermosolun rakenne
- **Dendriitit** = sy√∂tteet ($x_1, x_2, ‚Ä¶$)  
- **Synapsit** = painot (voivat kiihdytt√§√§ tai est√§√§)  
- **Solukeskus (soma)** = laskentayksikk√∂ (kuten lineaarinen malli + aktivointifunktio)  
- **Aksoni** = l√§ht√∂ ($y$)  

‚û°Ô∏è **Keinotekoinen neuroni = Sy√∂tteet √ó Painot ‚Üí Summataan ‚Üí Aktivointifunktio ‚Üí Ulostulo**

### 1.4 Huomioita
- Biologiset neuronit v√§litt√§v√§t signaaleja **piikkein√§**, kun taas keinotekoiset neuronit k√§ytt√§v√§t jatkuvia arvoja.  
- T√§m√§ johtaa uusiin tutkimusalueisiin kuten:  
  - **Spiking Neural Networks (SNNs)**  
  - **Neuromorfiset sirut**

### 1.5 Keinotekoinen neuroni lineaarisena mallina
- Keinotekoinen neuroni voidaan kuvata **lineaariseksi malliksi**: painotettujen sy√∂tteiden summa + bias.  
- T√§m√§ liittyy suoraan siihen, mit√§ olemme opiskelleet **lineaarisessa regressiossa** ja **luokittelussa**.  
- N√§m√§ aiheet toimivat perustana neuroverkkojen ymm√§rt√§miselle.  

---

## Osa 2 : Lineaarinen malli ja ensimm√§inen neuroverkkoaalto (1943)

![Board notes](/images/docs/mlLecture4_Neuralnetworks/2.png)

### 2.1 Neuroni lineaarisena mallina
- Neuroni voidaan mallintaa **sy√∂tteiden lineaarisena yhdistelm√§n√§** + bias:  
  $$
  y = \sum_i w_i x_i + w_0
  $$
- T√§m√§ j√§rjestelm√§ voi jo suorittaa **lineaarisen regression**.  
- Luokitteluun t√§m√§ ei kuitenkaan riit√§ ‚Üí tarvitaan kynnysfunktio tai ep√§lineaarinen aktivointi.  

### 2.2 Kohti luokittelua
- Bin√§√§riluokittelu: vain kaksi luokkaa (0/1).  
- Ratkaisu: k√§yt√§ **kynnysfunktiota** (tai my√∂hemmin sigmoid/logistista funktiota).  
- Koodissa:  
  - Lasketaan ensin painotettu summa.  
  - Sitten sovelletaan kynnyst√§ (tai sigmoidia) p√§√§t√∂ksen tekemiseksi.  

### 2.3 Historiallinen huomio ‚Äî Aalto 1 (1943)
- **McCulloch & Pitts (1943): Lineaarinen kynnysyksikk√∂ (LTU)**  
- M√§√§ritelm√§:  
  $$
  y = 
    \begin{cases}
      1 & \text{jos } w_1x_1 + w_2x_2 + w_0 \geq \theta \\
      0 & \text{jos } w_1x_1 + w_2x_2 + w_0 < \theta
    \end{cases}
  $$
- Tyypillisesti $\theta = 0$.  
- Motivaatio: simuloida logiikkaporteja (digitaalisten tietokoneiden perusta).  

### 2.4 Esimerkki: AND-portti
- Sy√∂tteet: $x_1, x_2 \in \{0,1\}$  
- Haluttu tulos: $y=1$ vain kun molemmat sy√∂tteet ovat 1.  
- Painot: $w_1 = w_2 = \tfrac{2}{3},\ w_0 = -1$  

Tarkistus:  
$$
\begin{aligned}
(0,0):\ & -1<0 \ \Rightarrow y=0 \\
(1,0)\ \text{tai}\ (0,1):\ & \tfrac{2}{3}-1=-\tfrac{1}{3}<0 \ \Rightarrow y=0 \\
(1,1):\ & \tfrac{4}{3}-1=\tfrac{1}{3}>0 \ \Rightarrow y=1
\end{aligned}
$$  

‚úÖ Toimii AND-porttina.  

### 2.5 Esimerkki: OR-portti
![Board notes](/images/docs/mlLecture4_Neuralnetworks/3.png)

- Sy√∂tteet: $x_1, x_2 \in \{0,1\}$  
- Haluttu tulos: $y=1$, jos jompikumpi sy√∂te on 1.  
- Painot (perusversio): $w_1 = w_2 = 1,\ w_0 = -1$  
  - (0,0): $-1<0 \Rightarrow y=0$  
  - (1,0) tai (0,1): $1-1=0 \Rightarrow y=1$  
  - (1,1): $2-1=1>0 \Rightarrow y=1$  

‚úÖ Toimii OR-porttina, mutta raja on herkk√§.  

Parannus: $w_1 = w_2 = \tfrac{3}{2},\ w_0 = -1$ antaa paremman marginaalin.  

### 2.6 Kotiteht√§v√§: NAND-portti
> Suunnittele **NAND-portti** LTU-mallilla.  
> - Vihje: NAND = NOT(AND).  
> - Aloita AND-portin painoista ja s√§√§d√§ niit√§.  

### 2.7 Yhteenveto
- Yksinkertainen LTU sopivilla painoilla voi toteuttaa loogisia funktioita.  
- T√§m√§ historiallinen askel osoitti, ett√§ hermoyksik√∂t voisivat teoriassa muodostaa laskennan perustan.  

---

## Osa 3 : Aalto 2 (1949) ‚Äî Hebbin oppiminen

![Board notes](/images/docs/mlLecture4_Neuralnetworks/4.png)

### 3.1 Hebbin oppimiss√§√§nt√∂
- Ehdotettiin painojen p√§ivitysmekanismiksi LTU:ssa.  
- P√§ivityss√§√§nt√∂:  
  $$
  w_i^{t+1} = w_i^t + \eta (y - \hat{y}) x
  $$
- Miss√§:  
  - $y$ = todellinen ulostulo (ground truth)  
  - $\hat{y}$ = arvioitu ulostulo  
  - virhe = $y - \hat{y}$  
  - $\eta$ = oppimisnopeus (esim. 0.1)  

### 3.2 Oppimisdynamiikka
- Jos arvio on liian korkea ‚Üí painot pienenev√§t.  
- Jos arvio on liian matala ‚Üí painot kasvavat.  
- Ajan my√∂t√§ painot konvergoivat pisteeseen, jossa $y \approx \hat{y}$.  

### 3.3 Oppimisnopeuden s√§√§t√∂
- Liian suuri $\eta$ voi aiheuttaa oskillaatiota (virhe ei asetu).  
- Ratkaisu: **pienenn√§ oppimisnopeutta v√§hitellen** varmistaaksesi konvergenssin.  

---

## Osa 4 : Yhden neuronin rajat ‚Äî XOR ja toinen talvi

![Board notes](/images/docs/mlLecture4_Neuralnetworks/5.png)

### 4.1 Lineaarinen erotettavuus
- Perceptron voi ratkaista vain ongelmat, joissa data on **lineaarisesti erotettavissa** (yksi viiva/hyper-taso jakaa luokat).  
- Esimerkki: AND, OR ovat ratkaistavissa.  

### 4.2 XOR-ongelma
- XOR-totuustaulu:  
  - (0,0) ‚Üí 0  
  - (1,0) ‚Üí 1  
  - (0,1) ‚Üí 1  
  - (1,1) ‚Üí 0  
- Ei lineaarisesti erotettavissa ‚Äî yksitt√§inen perceptron ei voi ratkaista t√§t√§.  

### 4.3 Toinen AI-talvi
- Vuonna 1969 Minsky & Papert osoittivat perceptronien rajoitukset (erityisesti XOR).  
- Johti skeptisyyteen ja rahoituksen v√§henemiseen ‚Üí ‚Äútoinen talvi.‚Äù  

### 4.4 Monikerrosidea
- Biologisilla aivoilla on **monia neuroneja, jotka toimivat yhdess√§**.  
- Jos yhdist√§mme useita neuroneja (piilokerros), XOR voidaan esitt√§√§.  
- Takaisinlevitysalgoritmi (1970‚Äì80-luvuilla) mahdollisti t√§llaisten verkkojen tehokkaan koulutuksen.  

---

## Osa 5 : Lineaarisesta ep√§lineaariseen ‚Äî Logistiikka, h√§vi√∂ & Gradienttilasku

![Board notes](/images/docs/mlLecture4_Neuralnetworks/6.png)

### 5.1 Aktivointifunktiot
- Siirty√§ksemme lineaarisesta regressiosta eteenp√§in k√§yt√§mme ep√§lineaarisia aktivointeja:  
  - **Sigmoid (logistinen):**  
    $$\sigma(z) = \frac{1}{1+e^{-z}} \quad \in (0,1)$$  
  - **Tanh:**  
    $$\tanh(z) \in (-1,1)$$  
  - Lineaarinen (identiteetti), ReLU jne. (my√∂hemm√§t kehitykset).  

### 5.2 H√§vi√∂funktiot
- Regressio: Keskivirhe (MSE)  
  $$L = \frac{1}{N} \sum (y - \hat{y})^2$$  
- Luokittelu: Ristiinentropia (esitell√§√§n my√∂hemmin).  

### 5.3 Gradienttilasku
- Laske h√§vi√∂n gradientti painojen suhteen:  
  $$\nabla_w L = \left( \frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial w_2}, ‚Ä¶ \right)$$  
- P√§ivityss√§√§nt√∂:  
  $$
  w^{(t+1)} = w^{(t)} - \eta \, \nabla_w L
  $$
- $\eta$: oppimisnopeus ‚Äî liian suuri ‚Üí divergenssi, liian pieni ‚Üí hidas oppiminen.  
- **Oppimisnopeuden s√§√§t√∂** auttaa konvergenssia.  

### 5.4 Universaalin approksimaation teoreema
- Kunhan on v√§hint√§√§n **yksi piilokerros** ja ep√§lineaarinen aktivointi, neuroverkko voi approksimoida *mink√§ tahansa* funktion (Cybenko 1989).  

### 5.5 Monikerroksiset perceptronit & Takaisinlevitys
![Board notes](/images/docs/mlLecture4_Neuralnetworks/7.png)

- **Yksitt√§inen LTU** ei voi ratkaista ongelmia kuten XOR.  
- Ratkaisu: yhdistet√§√§n useita neuroneja **monikerroksiseksi perceptroniksi (MLP)**.  
  - Esim.: kaksi piiloneuronia ($y_1, y_2$), jotka sy√∂tet√§√§n ulostuloneuroniin.  
  - T√§m√§ rakenne mahdollistaa ep√§lineaariset p√§√§t√∂srajat.  

- **H√§vi√∂funktio**: edelleen MSE.  
- **Koulutushaaste**: kuinka p√§ivitt√§√§ piilokerrosten painot?  

‚û°Ô∏è **Takaisinlevitysalgoritmi**  
- Lasketaan ulostulovirhe (ennusteen ja tavoitteen ero).  
- Levitet√§√§n virhe taaksep√§in ketjus√§√§nn√∂n avulla.  
- P√§ivitet√§√§n kaikki painot (sy√∂te ‚Üí piilo, piilo ‚Üí ulostulo) gradienttilaskulla.  

T√§m√§ l√§pimurto 1970‚Äì80-luvuilla mahdollisti syvien verkkojen k√§yt√§nn√∂n koulutuksen ja voitti XOR-rajoituksen.  

### 5.6 Moniluokkainen luokittelu

![Board notes](/images/docs/mlLecture4_Neuralnetworks/8.png)

- T√§h√§n asti tarkastelimme vain **bin√§√§riluokitusta** (0/1).  
- **Moniluokkaongelmissa (N luokkaa)**:  
  - Ulostulokerroksessa on **N neuronia**, yksi jokaista luokkaa varten.  
  - Esim.: 3 luokkaa ‚Üí ulostulo = $(y_1, y_2, y_3)$.  
- **Opetustiedot** esitet√§√§n **one-hot-koodauksella**:  
  - Luokka 1 ‚Üí (1, 0, 0)  
  - Luokka 2 ‚Üí (0, 1, 0)  
  - Luokka 3 ‚Üí (0, 0, 1)  
- Koulutuksessa:  
  - Forward pass: lasketaan kaikkien luokkien ulostulot.  
  - H√§vi√∂: usein **ristiinentropia** softmax-aktivoinnilla.  
  - Backward pass: levitet√§√§n virhe taaksep√§in kaikkien painojen l√§pi takaisinlevityksell√§.  

‚û°Ô∏è T√§m√§ yleistys mahdollistaa sen, ett√§ neuroverkot voivat k√§sitell√§ **mit√§ tahansa m√§√§r√§√§ luokkia**.  

---

## Osa 6 : Harjoitusta kehyksill√§ ‚Äî TensorFlow & PyTorch

![Board notes](/images/docs/mlLecture4_Neuralnetworks/9.png)

### 6.1 TensorFlow vs. PyTorch
- Molemmat ovat **nykyaikaisia syv√§oppimiskehyksi√§**.  

- **TensorFlow (Google)**  
  - Valittu t√§lle kurssille *‚Äúmonimuotoisuuden vuoksi.‚Äù*  
  - `Sequential` API on hyvin yksinkertainen: voit lis√§t√§ kerroksia yksi kerrallaan.  
  - Hyv√§ **ensimm√§iseksi neuroverkko-demoksi** (esim. lineaarinen regressio).  
  - Asennus voi antaa *‚Äúpieni√§ virheit√§‚Äù*, mutta se toimii silti.  

- **PyTorch (Meta/Facebook)**  
  - *‚ÄúPyTorch on minusta tulossa paljon suositummaksi kuin TensorFlow.‚Äù*  
  - Joustavampi ja l√§hemp√§n√§ raakaa Pythonia, parempi monimutkaisille malleille.  
  - *‚ÄúPyTorch on opettavaisempi, mutta my√∂s vaikeampi.‚Äù*  
  - K√§ytet√§√§n my√∂hemmin **Deep Learning -kurssilla**.  

- **Yhteenveto**  
  - **TensorFlow** ‚Üí helpompi, aloittelijayst√§v√§llinen, hyv√§ demoihin.  
  - **PyTorch** ‚Üí suositumpi tutkimuksessa, joustava, opettavampi mutta vaikeampi.  

- Lainaus luennolta:  
  > *‚ÄúKukaan ei tee takaisinlevityst√§ k√§sin, paitsi jos haluat oppia. Oikeassa ty√∂ss√§ k√§yt√§mme TensorFlow‚Äôta tai PyTorchia.‚Äù*  

---

### 6.2 Yksinkertainen regressio yhdell√§ neuronilla
- Malli: `Dense(units=1, activation="linear")`  
- Optimointimenetelm√§: SGD (stokastinen gradienttilasku).  
- H√§vi√∂: MSE.  
- Koulutus (`fit`) n√§ytt√§√§ virheen v√§henev√§n epookkien aikana.  
- ‚úÖ Oppii regressiosuoran (kuten lineaarinen regressio).  

---

### 6.3 Monikerroksinen perceptron (MLP) regressio
- Teht√§v√§: approksimoida **sinimuotoinen aalto**.  
- Sy√∂te: $t$ (aika).  
- Piilokerros: 50 neuronia, **sigmoid-aktivointi**.  
- Ulostulo: $y \approx \sin(t)$.  
- Demonstroi **Universaalin approksimaation teoreeman**:  
  - Riitt√§v√§ll√§ m√§√§r√§ll√§ neuroneja, jo yksi piilokerros voi approksimoida mink√§ tahansa funktion.  
- Koulutus vaatii **oppimisnopeuden** ja **epookkien** s√§√§t√§mist√§ virheen ja oskillaatioiden v√§hent√§miseksi.  

---

### 6.4 Luokittelu-esimerkki
- Teht√§v√§: luokitella ‚Äú**Hobitit vs. Haltijat**.‚Äù  
- Ulostulokerros: 2 neuronia (bin√§√§riluokittelu).  
- Tunnisteet koodataan **one-hot-koodauksella**:  
  - Hobitti ‚Üí (1,0)  
  - Haltija ‚Üí (0,1)  
- H√§vi√∂: ristiinentropia.  
- Tarkkuus paranee koulutuksen aikana (esim. 86% ‚Üí 92%).  

---

### 6.5 Kotiteht√§v√§
- Kokeile kouluttaa omia neuroverkkojasi **TensorFlow‚Äôssa**.  
- Kokeile:  
  - Eri oppimisnopeuksia.  
  - Useampia epookkeja.  
  - Lis√§√§ piiloneuroneja/kerroksia.  
- Haaste: p√§ihit√§ **Hebbin oppimisen** ja opettajan demojen tarkkuus.  

---

## Yhteenveto

1. **Aivoista neuroverkkoihin**  
   - Neuroverkot on inspiroitu biologisista neuroneista: sy√∂tteet, painot (synapsit), summaus ja aktivoinnit.  
   - Aivot osoittavat yhteyksien voiman (~$10^{13}$ synapsia).  

2. **Aalto 1 (1943): Lineaariset kynnysyksik√∂t**  
   - McCulloch & Pitts osoittivat, ett√§ yksitt√§iset neuronit voivat toteuttaa logiikkafunktioita (AND, OR, NAND).  
   - Mutta niill√§ ei ollut oppimismekanismia.  

3. **Aalto 2 (1949): Hebbin oppiminen**  
   - Toi ajatuksen painojen s√§√§t√§misest√§ virheen perusteella.  
   - Varhainen oppimismuoto, mutta herkk√§ oppimisnopeudelle ja konvergenssille.  

4. **Yhden neuronin rajat (XOR)**  
   - Perceptron voi ratkaista vain lineaarisesti erotettavia ongelmia.  
   - XOR paljasti t√§m√§n rajoituksen ‚Üí johti skeptisyyteen ja toiseen AI-talveen.  

5. **Ep√§lineaariset aktivoinnit & Takaisinlevitys**  
   - Logistinen/sigmoid, tanh ja muut aktivoinnit mahdollistavat ep√§lineaariset p√§√§t√∂srajat.  
   - Takaisinlevitys (1970‚Äì80-luvuilla) mahdollisti monikerroksisten perceptronien kouluttamisen.  
   - Universaalin approksimaation teoreema (1989): yksi piilokerros riitt√§√§ mink√§ tahansa funktion approksimointiin.  

6. **Nykyaikainen k√§yt√§nt√∂: TensorFlow & PyTorch**  
   - TensorFlow: helppo k√§ytt√§√§, hyv√§ demoihin, k√§ytet√§√§n t√§ll√§ kurssilla.  
   - PyTorch: joustava, suositumpi tutkimuksessa, k√§ytet√§√§n syv√§oppimiskurssilla.  
   - Kehykset tekev√§t regressioiden, luokitusten ja monikerrosverkkojen kouluttamisesta k√§yt√§nn√∂llist√§ ja skaalautuvaa.  

